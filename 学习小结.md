# 学习小结

## 2022.4.28~5.4

花了大约一周的零散时间在B站跟着大佬学了下爬虫。

本此主要利用的库 为 re(http请求库) beautifulsoup(靓汤，数据处理) xlwt（excel操作库）

流程可简单的概括为：															难点-----------------

1. 调用request请求访问的到web页面的HTML源码  （配置Agent 头 循环爬取）
2. beautifulsoup 添加正则 提取HTML信息                （填写正则表达式）
3. xlwt+列表 将提取的信息输入进 xls文件中 	         （列表+一些不需要的数据的处理）

主要用到的函数为：

```
def askURL(url):            （获取指定URL的源码）
```

```
def savaData(datalist,savepath):    （保存数据）
```

```
def getData(baseurl):             （整体利用+数据处理）
```